{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Baseline Classifier Performance\n",
        "\n",
        "This notebook runs a baseline classifier on multiple training subsets and evaluates on several validation sets, across multiple random seeds. Results (mean ± std) will serve as a reference when comparing later augmented models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports and Setup\n",
        "\n",
        "Load all necessary libraries, dataset helpers, and set up the device and loss function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46cd0967",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.insert(0, os.path.abspath('..'))\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from pkldataset import PKLDataset\n",
        "from helpers import set_seed, get_model, train_model, eval_model\n",
        "\n",
        "# Device and loss\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a03f51b4",
      "metadata": {},
      "source": [
        "## 2. Configuration\n",
        "\n",
        "- **Train paths**: directories containing pickle files for various subset sizes  \n",
        "- **Validation paths**: held-out datasets for evaluation  \n",
        "- **Seeds**: for estimating training stability\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b582f486",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training subsets (folders w pkl files)\n",
        "train_paths = [\n",
        "    \"../datasets/RPDC197/train_20\",\n",
        "    \"../datasets/RPDC197/train_50\",\n",
        "    \"../datasets/RPDC197/train_100\",\n",
        "    \"../datasets/RPDC197/train_200\",\n",
        "    \"../datasets/RPDC197/train_300\",\n",
        "    \"../datasets/RPDC197/train_400\",\n",
        "    \"../datasets/RPDC197/train_500\",\n",
        "    \"../datasets/RPDC197/train_600\",\n",
        "]\n",
        "\n",
        "# Validation sets\n",
        "val_paths = [\n",
        "    \"../datasets/RPDC185/val_1000\",\n",
        "    \"../datasets/RPDC188/val_1000\",\n",
        "    \"../datasets/RPDC191/val_1000\",\n",
        "    \"../datasets/RPDC194/val_1000\",\n",
        "    \"../datasets/RPDC197/val_1000\",\n",
        "]\n",
        "\n",
        "# Seeds for reproducibility\n",
        "seeds = [101, 202, 303, 404, 505, 606, 707, 808, 909, 1001]\n",
        "\n",
        "# Prepare results container: {train_path: {val_path: [accuracies]}}\n",
        "results = {tp: {vp: [] for vp in val_paths} for tp in train_paths}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ab14ac9",
      "metadata": {},
      "source": [
        "## 3. Multi-Seed Training & Evaluation Loop\n",
        "\n",
        "For each seed:\n",
        "1. Set the random seed  \n",
        "2. For each training subset:\n",
        "   - Load data  \n",
        "   - Instantiate model, optimizer, scheduler  \n",
        "   - Train for 50 epochs  \n",
        "3. Evaluate on every validation set and record accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8095340c",
      "metadata": {},
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    for seed in seeds:\n",
        "        print(f\"\\n=== Seed {seed} ===\")\n",
        "        set_seed(seed)\n",
        "\n",
        "        for tp in train_paths:\n",
        "            print(f\"-- Training on {tp}\")\n",
        "            ds_real = PKLDataset(tp)\n",
        "            train_loader = DataLoader(ds_real, batch_size=32, shuffle=True)\n",
        "\n",
        "            model = get_model().to(device)\n",
        "            optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)\n",
        "\n",
        "            model = train_model(\n",
        "                model,\n",
        "                train_loader,\n",
        "                criterion,\n",
        "                optimizer,\n",
        "                scheduler,\n",
        "                num_epochs=50,\n",
        "                device=device\n",
        "            )\n",
        "\n",
        "            for vp in val_paths:\n",
        "                val_loader = DataLoader(PKLDataset(vp), batch_size=64, shuffle=False)\n",
        "                acc = eval_model(model, val_loader, device)\n",
        "                results[tp][vp].append(acc)\n",
        "                print(f\"[{tp} -> {vp}] Seed {seed}: Acc = {acc:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Summary of Results\n",
        "\n",
        "Compute mean and standard deviation of accuracy across seeds for each (train → val) pair.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n=== Summary across seeds ===\")\n",
        "for tp in train_paths:\n",
        "    for vp in val_paths:\n",
        "        arr = np.array(results[tp][vp])\n",
        "        mean, std = arr.mean(), arr.std(ddof=1)\n",
        "        print(f\"{tp} -> {vp}: Mean = {mean:.2f}%, Std = {std:.2f}%\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "hiwi",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
