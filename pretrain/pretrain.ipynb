{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from pkldataset import PKLDataset\n",
    "from helpers import set_seed, get_model, eval_model, train_model\n",
    "\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "train_path_1     = r\"C:\\Users\\gus07\\Desktop\\data hiwi\\preprocessing\\HC\\T197\\RP\"# add path to pretrain folder here (e.g. \"RPHC197\")\n",
    "# Training dataset names\n",
    "transfer_sets = [\"../datasets/RPDC197/train_20\", \"../datasets/RPDC197/train_50\", \"../datasets/RPDC197/train_100\", \"../datasets/RPDC197/train_200\", \"../datasets/RPDC197/train_300\",\n",
    " \"../datasets/RPDC197/train_400\", \"../datasets/RPDC197/train_500\", \"../datasets/RPDC197/train_600\"]\n",
    "\n",
    "# Validation datasets to test each model on\n",
    "val_paths = [\n",
    "    \"../datasets/RPDC185/val_1000\",\n",
    "    \"../datasets/RPDC188/val_1000\",\n",
    "    \"../datasets/RPDC191/val_1000\",\n",
    "    \"../datasets/RPDC194/val_1000\",\n",
    "    \"../datasets/RPDC197/val_1000\",\n",
    "]\n",
    "seeds            = [101,202,303,404,505,606,707,808,909,1001]\n",
    "device           = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion        = nn.CrossEntropyLoss()\n",
    "\n",
    "# Prepare results container\n",
    "# results[train_t][val_path] = list of accuracies (one per seed)\n",
    "results = {\n",
    "    t: {vp: [] for vp in val_paths}\n",
    "    for t in transfer_sets\n",
    "}\n",
    "\n",
    "for seed in seeds:\n",
    "    print(f\"\\n>>> Full pipeline with seed {seed}\")\n",
    "    set_seed(seed)\n",
    "\n",
    "    # --- FIRST PHASE on train_path_1 ---\n",
    "    train_ds, val_ds = PKLDataset.split_dataset(train_path_1)\n",
    "    train_loader1 = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "    val_loader1   = DataLoader(val_ds,   batch_size=64, shuffle=True)\n",
    "\n",
    "    model = get_model().to(device)\n",
    "    opt   = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "    sch   = optim.lr_scheduler.StepLR(opt, step_size=50, gamma=0.1)\n",
    "\n",
    "    model = train_model(\n",
    "        model, train_loader1,\n",
    "        criterion, opt, sch,\n",
    "        num_epochs=10,\n",
    "        device=device\n",
    "    )\n",
    "    # keep pretrained weights in memory\n",
    "    pretrained_state = model.state_dict()\n",
    "\n",
    "    # --- SECOND PHASE (TRANSFER) ---\n",
    "    for t in transfer_sets:\n",
    "        # reload pretrained\n",
    "        tl_model = get_model().to(device)\n",
    "        tl_model.load_state_dict(pretrained_state)\n",
    "\n",
    "        # train on t\n",
    "        loader_t = DataLoader(PKLDataset(t), batch_size=64, shuffle=True)\n",
    "        opt2     = optim.Adam(tl_model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "        sch2     = optim.lr_scheduler.StepLR(opt2, step_size=25, gamma=0.1)\n",
    "\n",
    "        tl_model = train_model(\n",
    "            tl_model, loader_t,\n",
    "            criterion, opt2, sch2,\n",
    "            num_epochs=100,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # evaluate on each val_path\n",
    "        for vp in val_paths:\n",
    "            loader_vp = DataLoader(PKLDataset(vp), batch_size=64, shuffle=False)\n",
    "            acc       = eval_model(tl_model, loader_vp, device)\n",
    "            results[t][vp].append(acc)\n",
    "            print(f\"  [Seed {seed}] {t} → {vp}: {acc:.2f}%\")\n",
    "\n",
    "# --- FINAL SUMMARY ---\n",
    "print(\"\\n=== Mean ± Std Dev over seeds ===\")\n",
    "for t in transfer_sets:\n",
    "    for vp in val_paths:\n",
    "        acc_list = results[t][vp]\n",
    "        mean_acc = np.mean(acc_list)\n",
    "        std_acc  = np.std(acc_list, ddof=1)\n",
    "        print(f\"{t} → {vp}: mean = {mean_acc:.2f}%,  std = {std_acc:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hiwi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
